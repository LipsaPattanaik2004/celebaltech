# Summer Internship |  Celebal Technologies
__________________
This repository documents my on-campus Data Science internship at Celebal Technologies, where I gained hands-on experience in Python programming, data analysis, machine learning techniques, SQL, and introductory Generative AI concepts through structured weekly learning and applied assignments.

## Overview
_______________________
- During this internship, I worked through a progressive curriculum covering core programming fundamentals, data science workflows, and machine learning models. The focus was on applying theoretical concepts to practical datasets, building reusable code, and developing an end-to-end understanding of data-driven problem solving.
- The internship concluded with successful project submissions and certification based on performance and feedback.

## Internship Timeline & Learning Outcomes
_______________________
### Python Fundamentals
- Strengthened understanding of Python syntax, data types, control flow, and standard libraries  
- Developed problem-solving skills through hands-on programming exercises  

### Object-Oriented Programming
- Implemented classes, inheritance, abstraction, and encapsulation  
- Applied OOP principles to build modular and maintainable code  

### Data Analysis with Python
- Performed data manipulation and analysis using Pandas and NumPy  
- Conducted exploratory data analysis to identify trends and patterns  

### Feature Engineering
- Applied data preprocessing techniques such as scaling, encoding, and imputation  
- Engineered features to improve machine learning model performance  

### Regression Modeling
- Built and evaluated linear, logistic, and ridge regression models  
- Used RMSE, R² score, and visual diagnostics for performance evaluation  

### Clustering Techniques
- Implemented K-Means, DBSCAN, and hierarchical clustering  
- Evaluated clustering quality using Elbow Method and Silhouette Score  

### SQL Fundamentals
- Practiced DDL, DML, and TCL commands  
- Executed complex queries using joins, subqueries, and aggregations  

### Generative AI Exposure
- Explored prompt engineering and basic automation workflows  
- Studied responsible AI usage and ethical considerations  

## Tools & Technologies
Languages: Python, SQL  
Libraries: Pandas, NumPy, Scikit-learn, Matplotlib  
Databases: MySQL, SQL Server  
Visualization: Power BI, Tableau, Excel  
Deployment & Apps: Streamlit  
Version Control: Git, GitHub  

## Repository Structure
lipsa_project/
├── data/                 # Datasets used for analysis
├── notebooks/            # Feature engineering and ML notebooks
├── sql_scripts/          # SQL practice and query scripts
├── genai/                # Prompt examples and GenAI notes
├── dashboards/           # Visualization and dashboard files
├── requirements.txt      # Python dependencies
└── README.md

- Clone the repository:
git clone https://github.com/LipsaPattanaik2004/lipsa_project.git
- Navigate to the project directory:
cd lipsa_project
- Install dependencies:
pip install -r requirements.txt
- Open notebooks:
jupyter notebook notebooks/feature_engineering.ipynb

## Outcomes
_______________
- Built a strong foundation in Python-based data analysis and machine learning workflows  
- Applied SQL for structured data querying, transformation, and analysis  
- Developed end-to-end data pipelines from preprocessing and feature engineering to model evaluation  
- Gained practical exposure to regression, clustering, and exploratory data analysis techniques  
- Acquired introductory experience with Generative AI concepts in analytics use cases  

## Future Enhancements
_____________________
- Integrate complete end-to-end automated data pipelines  
- Deploy analytical models and dashboards using Streamlit  
- Incorporate advanced machine learning and optimization techniques  
- Use real-world, large-scale datasets for deeper analysis  
- Enable cloud-based data storage, processing, and orchestration

# LIPSA PATTANAIK | ITER, SOA UNIVERSITY





