{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4bef58f-52c9-4dad-8168-2ebb89b1b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\anacondacustom\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in e:\\anacondacustom\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in e:\\anacondacustom\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\anacondacustom\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\anacondacustom\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anacondacustom\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anacondacustom\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anacondacustom\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anacondacustom\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anacondacustom\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn pandas scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfbbf8-aa1f-471c-8574-62fd434895a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "// https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f711d9e-3e01-4c78-b3dd-0d77bca71cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "// https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f23772-ed36-4f1d-b67f-df77ec2e93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Clustering Labels (first 10): [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10, algorithm='lloyd')\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(\"K-Means Clustering Labels (first 10):\", kmeans_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc269e7-fc94-49d6-a04f-ad574c0941d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering Labels (first 10): [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agg = AgglomerativeClustering(n_clusters=2)\n",
    "agg_labels = agg.fit_predict(X_scaled)\n",
    "print(\"Hierarchical Clustering Labels (first 10):\", agg_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0002626-3b52-47a4-a1dd-218a7e874943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Labels (first 10): [-1 -1 -1 -1 -1 -1  0 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=2.0, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "print(\"DBSCAN Labels (first 10):\", dbscan_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6922bf6b-565a-4e7c-81d0-776bc7facd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM Labels (first 10): [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm_labels = gmm.fit_predict(X_scaled)\n",
    "print(\"GMM Labels (first 10):\", gmm_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d3e672-96b9-4468-9e66-ca512b6bb9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularization (Logistic Regression)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l1_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "l1_model.fit(X_train, y_train)\n",
    "l1_pred = l1_model.predict(X_test)\n",
    "print(\"L1 Regularization (Logistic Regression)\\n\", classification_report(y_test, l1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db76e82f-8d8f-4c46-b9e1-e2d37aef0064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularization (Logistic Regression)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l2_model = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "l2_model.fit(X_train, y_train)\n",
    "l2_pred = l2_model.predict(X_test)\n",
    "print(\"L2 Regularization (Logistic Regression)\\n\", classification_report(y_test, l2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceef79fe-3a73-4fff-9a8e-6037a4a14b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         0\n",
      "         0.0       0.97      0.91      0.94        43\n",
      "         1.0       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.64      0.63      0.64       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "elastic_model = ElasticNetCV(cv=5)\n",
    "elastic_model.fit(X_train, y_train)\n",
    "elastic_preds = np.round(elastic_model.predict(X_test))\n",
    "print(\"ElasticNet Regression\\n\", classification_report(y_test, elastic_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f20a5d0-55e7-4ddb-a6b3-cb3269e223dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(\"Random Forest\\n\", classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33bf21b4-2824-43f4-9741-7302dfccdded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "print(\"Gradient Boosting\\n\", classification_report(y_test, gb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b992ce4-dbbe-4071-93ad-03372cf0d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "bag.fit(X_train, y_train)\n",
    "bag_pred = bag.predict(X_test)\n",
    "print(\"Bagging\\n\", classification_report(y_test, bag_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b25fe417-4786-457a-a267-6e066f4cfd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "boost = AdaBoostClassifier(n_estimators=50)\n",
    "boost.fit(X_train, y_train)\n",
    "boost_pred = boost.predict(X_test)\n",
    "print(\"AdaBoost\\n\", classification_report(y_test, boost_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfae69f-da8f-4953-9940-baa1afa63cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "base_learners = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('tree', DecisionTreeClassifier())\n",
    "]\n",
    "stack = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n",
    "stack.fit(X_train, y_train)\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Stacking Classifier\\n\", classification_report(y_test, stack_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893b2c4d-f033-498c-a4e9-a927ddc0d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, log_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12691e7d-db32-4e3e-b62d-b57dd0384dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        43\n",
      "           1       0.94      0.96      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "print(\"Decision Tree:\\n\", classification_report(y_test, tree_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a36823-d23b-466d-9e19-d04727a0eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b06fb093-a203-48ff-91de-3f6d40238893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "print(\"SVM:\\n\", classification_report(y_test, svm_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5403d285-b016-433f-8065-694e5a31e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.99      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.99       114\n",
      "   macro avg       0.99      0.99      0.99       114\n",
      "weighted avg       0.99      0.99      0.99       114\n",
      "\n",
      "Best Params: {'C': 0.1, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_lr = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='f1')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "grid_lr_pred = grid_lr.predict(X_test)\n",
    "print(\"Tuned Logistic Regression:\\n\", classification_report(y_test, grid_lr_pred))\n",
    "print(\"Best Params:\", grid_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bbeedb8-755a-4c70-843c-e031e6512ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Best Params: {'max_depth': None, 'min_samples_split': 6, 'n_estimators': 152}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist_rf = {'n_estimators': randint(50, 200), 'max_depth': [None, 10, 20], 'min_samples_split': randint(2, 10)}\n",
    "rand_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist_rf, n_iter=10, cv=5, scoring='f1', random_state=42)\n",
    "rand_rf.fit(X_train, y_train)\n",
    "rand_rf_pred = rand_rf.predict(X_test)\n",
    "print(\"Tuned Random Forest:\\n\", classification_report(y_test, rand_rf_pred))\n",
    "print(\"Best Params:\", rand_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce920d7f-c02f-4423-b4da-2275994ac8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression F1 Score: 0.9930\n",
      "Tuned Random Forest F1 Score: 0.9722\n",
      "\n",
      "Best Performing Model: Tuned Logistic Regression with F1 Score: 0.9930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tuned_models = {\n",
    "    \"Tuned Logistic Regression\": grid_lr.best_estimator_,\n",
    "    \"Tuned Random Forest\": rand_rf.best_estimator_,\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, pred)\n",
    "    print(f\"{name} F1 Score: {score:.4f}\")\n",
    "    if score > best_f1:\n",
    "        best_model = name\n",
    "        best_f1 = score\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model} with F1 Score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dc8ce-896a-4147-a630-b6df251e2673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
